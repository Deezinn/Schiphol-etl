# Schiphol ETL Pipeline

## âœˆï¸ VisÃ£o Geral

O **Schiphol ETL** Ã© um projeto de engenharia de dados desenvolvido em Python com o objetivo de **extrair, transformar e carregar (ETL)** dados pÃºblicos do **Aeroporto de Schiphol (Amsterdam Airport Schiphol)** para um banco de dados relacional, seguindo **boas prÃ¡ticas de arquitetura, separaÃ§Ã£o por camadas e validaÃ§Ã£o de dados**.

O projeto foi pensado para ser **modular, extensÃ­vel e profissional**, simulando um cenÃ¡rio real de pipeline de dados utilizado em ambientes corporativos.

---

## ğŸŒ O que Ã© o Aeroporto de Schiphol?

O **Amsterdam Airport Schiphol (AMS)** Ã© um dos maiores e mais importantes aeroportos da Europa, servindo como hub internacional para voos comerciais, cargas e conexÃµes globais.

A API pÃºblica do Schiphol disponibiliza informaÃ§Ãµes como:

* âœˆï¸ Voos (chegadas e partidas)
* ğŸ›« Tipos de aeronaves
* ğŸ¢ Companhias aÃ©reas
* ğŸŒ Destinos

Esses dados sÃ£o ideais para estudos de **ETL, modelagem de dados, validaÃ§Ã£o, observabilidade e persistÃªncia**.

---

## ğŸ§  Arquitetura do Projeto

O projeto segue uma **arquitetura inspirada em Clean Architecture / DDD**, separando responsabilidades em camadas bem definidas:

```text
src/
â”œâ”€â”€ app/                # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ domain/             # Regras de negÃ³cio e entidades
â”œâ”€â”€ pipeline/           # OrquestraÃ§Ã£o do ETL (extract, transform, load)
â”œâ”€â”€ infrastructure/     # Banco de dados, ORM, schemas e conexÃµes
â”œâ”€â”€ settings/           # ConfiguraÃ§Ãµes, logging e observabilidade
```

### ğŸ”¹ Domain

Camada mais importante do projeto.

* **Entities**: modelos de domÃ­nio (nÃ£o dependem de banco ou framework)
* **Interfaces**: contratos para extract / transform / load
* **Exceptions**: exceÃ§Ãµes especÃ­ficas do pipeline

> Aqui estÃ¡ a regra de ouro: **o domÃ­nio nÃ£o conhece infraestrutura**.

---

## ğŸ“¦ Tecnologias Utilizadas

O projeto utiliza um conjunto de bibliotecas modernas e amplamente usadas em **engenharia de dados** e **back-end em Python**:

### ğŸ Python 3.12

Linguagem principal do projeto.

---

### ğŸ¼ Pandas

Utilizado principalmente para:

* ExploraÃ§Ã£o inicial dos dados
* PrototipaÃ§Ã£o do ETL (notebooks)
* ManipulaÃ§Ã£o e normalizaÃ§Ã£o de dados tabulares

> O uso de Pandas estÃ¡ concentrado na fase exploratÃ³ria, evitando dependÃªncia excessiva no pipeline final.

---

### ğŸ“˜ Pydantic

Utilizado para:

* ValidaÃ§Ã£o rigorosa dos dados vindos da API do Schiphol
* Garantia de tipagem forte
* ConversÃ£o segura de dados externos

Responsabilidades principais:

* Garantir que campos obrigatÃ³rios nÃ£o sejam `None`
* Validar estruturas complexas (dicts, listas, datas)
* Evitar dados inconsistentes chegando ao banco

---

### ğŸ—„ï¸ SQLAlchemy

ResponsÃ¡vel pela **camada de persistÃªncia**:

* Mapeamento ORM (models)
* DefiniÃ§Ã£o de entidades de banco
* CriaÃ§Ã£o e gerenciamento de sessÃµes
* IntegraÃ§Ã£o com PostgreSQL

A separaÃ§Ã£o Ã© clara:

* **Schemas**: representaÃ§Ã£o dos dados
* **Models**: mapeamento ORM
* **Connections**: conexÃ£o com o banco

---

### ğŸ§¬ Alembic *(nÃ£o aplicado ainda)*

A biblioteca **Alembic** jÃ¡ estÃ¡ incluÃ­da no projeto, com o objetivo de:

* Versionamento de schema
* Controle de migraÃ§Ãµes de banco de dados

> âš ï¸ No estado atual do projeto, **as migraÃ§Ãµes ainda nÃ£o foram implementadas**. A criaÃ§Ã£o de tabelas Ã© feita via script Python.

---

### ğŸŒ Requests

Utilizado para:

* Consumo da API pÃºblica do Schiphol
* ComunicaÃ§Ã£o HTTP de forma simples e explÃ­cita

Bibliotecas auxiliares:

* **types-requests** â†’ tipagem estÃ¡tica

---

### ğŸ§ª Tipagem e Qualidade de CÃ³digo

* **pandas-stubs** â†’ tipagem estÃ¡tica para DataFrames
* Tipagem explÃ­cita em entidades, schemas e interfaces

---

### ğŸ˜ PostgreSQL

Banco de dados relacional utilizado para persistÃªncia dos dados.

Driver:

* **psycopg2-binary**

---

### ğŸ” python-dotenv

Utilizado para:

* Gerenciamento de variÃ¡veis de ambiente
* SeparaÃ§Ã£o entre cÃ³digo e credenciais sensÃ­veis

---

### ğŸ“Š Logfire (Pydantic)

O projeto utiliza **Logfire** para observabilidade:

* Rastreamento de execuÃ§Ãµes
* Logs estruturados
* Monitoramento do pipeline

Ao rodar o projeto, um link de observabilidade Ã© gerado automaticamente:

```text
Logfire project URL: https://logfire-us.pydantic.dev/deezinn/schiphol-etl
```

---

### ğŸš« Apache Airflow *(nÃ£o utilizado)*

Embora o projeto tenha uma estrutura **compatÃ­vel com orquestraÃ§Ã£o**, o **Apache Airflow ainda nÃ£o foi aplicado**.

A arquitetura atual facilita uma futura integraÃ§Ã£o com:

* DAGs
* Schedulers
* Observabilidade avanÃ§ada

---

### ğŸ—„ï¸ SQLAlchemy

ResponsÃ¡vel pela **camada de persistÃªncia**:

* Mapeamento ORM (models)
* CriaÃ§Ã£o de tabelas
* ConexÃ£o com PostgreSQL

A separaÃ§Ã£o Ã© clara:

* **Schemas**: representaÃ§Ã£o dos dados
* **Models**: mapeamento ORM
* **Connections**: conexÃ£o com o banco

---

### ğŸ“Š Logfire (Pydantic)

O projeto utiliza **Logfire** para observabilidade:

* Rastreamento de execuÃ§Ãµes
* Logs estruturados
* Monitoramento do pipeline

Ao rodar o projeto, um link de observabilidade Ã© gerado automaticamente:

```text
Logfire project URL: https://logfire-us.pydantic.dev/deezinn/schiphol-etl
```

---

### ğŸ³ Docker & Docker Compose

O projeto jÃ¡ estÃ¡ preparado para execuÃ§Ã£o em containers:

* Banco de dados PostgreSQL
* Ambiente isolado
* Facilidade de deploy

---

## ğŸ”„ Pipeline ETL

O pipeline segue o fluxo clÃ¡ssico:

1. **Extract**

   * Consome dados da API do Schiphol

2. **Transform**

   * NormalizaÃ§Ã£o
   * ConversÃ£o de tipos
   * ValidaÃ§Ã£o com Pydantic
   * Mapeamento domÃ­nio â†’ persistÃªncia

3. **Load**

   * InserÃ§Ã£o no PostgreSQL via SQLAlchemy

---

## ğŸ§ª Notebooks

A pasta `notebooks/` contÃ©m **prototipaÃ§Ãµes iniciais do ETL**, usadas para:

* Explorar os dados da API
* Testar transformaÃ§Ãµes
* Validar modelos

Eles serviram como base para a implementaÃ§Ã£o final do pipeline.

---

## âš™ï¸ Como Rodar o Projeto

### 1ï¸âƒ£ Clone o repositÃ³rio

```bash
git clone <repo-url>
cd Schiphol-etl
```

---

### 2ï¸âƒ£ Crie e ative o ambiente virtual

```bash
python3 -m venv .venv
source .venv/bin/activate
```

---

### 3ï¸âƒ£ Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Configure as credenciais

Edite o arquivo:

```text
src/infrastructure/security/credentials.py
```

Inclua:

* Credenciais da API do Schiphol
* Dados de conexÃ£o com o PostgreSQL

---

### 5ï¸âƒ£ Suba os serviÃ§os com Docker (opcional)

```bash
docker-compose up -d
```

---

### 6ï¸âƒ£ Crie as tabelas no banco

```bash
python3 -m src.settings.create_table
```

---

### 7ï¸âƒ£ Execute o pipeline

```bash
python3 -m src.app.main
```

---

## ğŸ“ Logs

Os logs sÃ£o armazenados em:

```text
logs/
â””â”€â”€ teste.log
```

AlÃ©m disso, toda a execuÃ§Ã£o pode ser acompanhada pelo **Logfire**.

---

## ğŸš€ Objetivos do Projeto

Este projeto foi desenvolvido com foco em:

* Engenharia de Dados profissional
* Arquitetura limpa
* ValidaÃ§Ã£o forte de dados
* Observabilidade
* Escalabilidade

Ã‰ um excelente exemplo de pipeline realista para:

* PortfÃ³lio
* Estudos avanÃ§ados de ETL
* Base para orquestraÃ§Ã£o com Airflow futuramente

---

## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT. Consulte o arquivo `LICENSE` para mais detalhes.

---

## ğŸ‘¨â€ğŸ’» Autor

Projeto desenvolvido por **AndrÃ© Luiz**, com foco em boas prÃ¡ticas de engenharia de dados, Python moderno e arquitetura de software.

---

Se quiser evoluir este projeto para **Airflow, CI/CD ou Data Lake**, ele jÃ¡ estÃ¡ pronto estruturalmente para isso.
